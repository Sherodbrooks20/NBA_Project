{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "0ad8bde7-e095-4d81-99fa-a82ad6e0b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\shero\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\shero\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\shero\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shero\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shero\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "be837948-90ce-4d2a-8429-286977b0f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "38901cc4-8693-4e57-bb53-07e2066381e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the major csv files, to work on them and edit the datasets\n",
    "df_sea = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\Copy of seasons(updated).csv\")\n",
    "df_cpl = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\Copy of players(updated).csv\")\n",
    "df_phw = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\Copy of players_height_weight(updated).csv\")\n",
    "df_ndd = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\nba_draft_data.csv\")\n",
    "\n",
    "# reading in sql edited csv files, to work on them and edit the datasets\n",
    "df_ms = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\main_stats.csv\")\n",
    "df_pl = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\players.csv\")\n",
    "df_pm = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\players_measure.csv\")\n",
    "df_as = pd.read_csv(r\"C:\\Users\\shero\\Downloads\\NBA Project\\advanced_stats_temp.csv\")\n",
    "\n",
    "#df_sea\n",
    "#df_cpl\n",
    "#df_phw\n",
    "#df_ndd\n",
    "\n",
    "#df_ms\n",
    "#df_pl\n",
    "#df_pm\n",
    "#df_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "81c9342f-7193-47b9-8fc3-ca45b79dd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the datatypes of each dataset, to get a better understanding of the dataset and how I should edit/analyze the data\n",
    "#df_sea.info()\n",
    "#df_cpl.info()\n",
    "#df_phw.info()\n",
    "#df_ndd.info()\n",
    "\n",
    "#df_ms.info()\n",
    "#df_pl.info()\n",
    "#df_pm.info()\n",
    "#df_as.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "c23422c0-3100-4cf8-a624-d3c3cae2edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the positions to match each other across datasets, to make it easier to merge them \n",
    "\n",
    "df_sea['Pos'] = df_sea['Pos'].replace({'PG':'Guard', 'SG':'Guard', 'SF': 'Wing', 'PF': 'Big', 'C':'Big'})\n",
    "df_cpl['position'] = df_cpl['position'].replace({'PG':'Guard', 'SG':'Guard', 'SF': 'Wing', 'PF': 'Big', 'C':'Big'})\n",
    "df_as['Pos'] = df_as['Pos'].replace({'PG':'Guard', 'SG':'Guard', 'SF': 'Wing', 'PF': 'Big', 'C':'Big'})\n",
    "\n",
    "#updating columns name to merge the dataets\n",
    "df_sea = df_sea.rename(columns={\"Player\":\"player\"})\n",
    "df_cpl = df_cpl.rename(columns={\"name\":\"player\"})\n",
    "df_phw = df_phw.rename(columns={\"Player\":\"player\"})\n",
    "\n",
    "df_pl = df_pl.rename(columns={\"name\": \"player\"})\n",
    "df_as = df_as.rename(columns={\"Player\":\"player\"})\n",
    "\n",
    "df_ndd = df_ndd.rename(columns={'pts_per_g':'ppg'})\n",
    "df_ndd = df_ndd.rename(columns={'fg_pct':'fg'})\n",
    "df_ndd = df_ndd.rename(columns={'fg3_pct':'3p'})\n",
    "df_ndd = df_ndd.rename(columns={'ft_pct':'ft'})\n",
    "df_ndd = df_ndd.rename(columns={'mp_per_g':'mpg'})\n",
    "df_ndd = df_ndd.rename(columns={'trb_per_g':'rbg'})\n",
    "df_ndd = df_ndd.rename(columns={'ast_per_g':'asg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "73d944e3-561e-46b3-b5bb-962d1f312329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge multiple datasets, to get one dataset that has all I need to start analyzing the data\n",
    "\n",
    "#df_full_player_demos\n",
    "df_fpw = df_ms.merge(df_pl, on = 'player', how = \"outer\").merge(\n",
    "    df_pm, on = 'player', how = \"outer\").merge(\n",
    "    df_as, on = 'player', how = \"outer\").merge(\n",
    "    df_ndd, on = 'player', how = \"outer\")\n",
    "\n",
    "# shows all columns, so I can select the ones I want\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_fpw = df_fpw.rename(columns= {'college_x': 'college', 'g_x':'g', '2p_x':'2p',\n",
    "'ppg_x':'ppg', 'asg_x':'asg','rbg_x':'rbg','fg_x':'fg','ft_x':'ft', 'mpg_x':'mpg'})\n",
    "\n",
    "# filtering the columns desired\n",
    "df_fpw = df_fpw[['player','pick_overall', 'college', 'birth_state','height','weight', 'position', \n",
    "\"ppg\", 'asg', 'rbg', 'fg', '3P','2p', 'ft', 'stl', 'blk', 'g', 'gs', 'mpg']]\n",
    "\n",
    "# cleaning up the merged column names\n",
    "\n",
    "#df_fpw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "id": "a8a9b563-3154-4ccc-98f3-d5c2f789fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates from datasets\n",
    "df_fpw = df_fpw.groupby('player', as_index = False).agg({ 'pick_overall':'first','college':'first', 'height':'first', 'weight':'first', \n",
    "    'position':'first', 'ppg':'mean', 'asg':'mean', 'rbg':'mean', 'fg':'mean', \n",
    "    '3P':'mean', '2p': 'mean', 'ft':'mean', 'stl':'mean', 'blk':'mean','g':'mean','gs':'mean', 'mpg':'mean'})\n",
    "\n",
    "df_as = df_as.groupby('player', as_index = False).agg({\n",
    "    'Pos':'first','PER':'mean', 'TS':'mean', 'USG':'mean', \n",
    "    'WS':'mean', 'FG':'mean', '3p':'mean', '2p':'mean', 'eFG%':'mean', \n",
    "    'FT':'mean'})\n",
    "\n",
    "#df_sea = df_sea.groupby('player', as_index = False).agg({  'Pos': 'first', 'PER': 'mean',  'TS%': 'mean', 'USG%': 'mean', 'WS': 'mean', 'FG%':'mean',\n",
    "    #'3PPercentage':'mean','2p/Dis':'mean','eFG%':'mean','FT/Dis':'mean','RBG':'mean','ASG':'mean','STL/Dis':'mean','BLK/Dis':'mean','TPG':'mean',\n",
    "    #'PFG':'mean','PPG':'mean'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "665c99dd-2f4a-4570-ac6e-21a25c791396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NaN values with 0, to get a cleaner looking dataset\n",
    "df_sea = df_sea.fillna(0)\n",
    "df_cpl = df_cpl.fillna(0)\n",
    "df_phw = df_phw.fillna(0)\n",
    "df_ndd = df_ndd.fillna(0)\n",
    "\n",
    "df_ms = df_ms.fillna(0)\n",
    "df_pl = df_pl.fillna(0)\n",
    "df_pm = df_pm.fillna(0)\n",
    "df_as = df_as.fillna(0)\n",
    "\n",
    "df_fpw = df_fpw.fillna(0)\n",
    "df_pick = df_pick.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "e9a29aa4-dee2-448f-886f-cc991d3c47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows the have no major stats data\n",
    "\n",
    "df_fpw = df_fpw[(df_fpw['g'] > 0)]\n",
    "\n",
    "# assigning positions to rows that don't have them by height\n",
    "def assign_position(height):\n",
    "    if height < 6.3:\n",
    "        return 'Guard'\n",
    "    elif 6.3 < height < 6.8:\n",
    "        return 'Wing'\n",
    "    else:\n",
    "        return 'Big'\n",
    "        \n",
    "df_fpw['position'] = df_fpw.apply(lambda row: assign_position(row['height']) if row['position'] == 0 else row['position'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "885d1171-74cd-45f6-9e6b-003be68ce976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position based analysis\n",
    "\n",
    "# getting descriptive stats by position -------------------------\n",
    "Pos_stats = df_fpw.groupby('position')[['ppg','asg','rbg','stl','blk']].agg(['mean', 'median', 'min', 'max'])\n",
    "\n",
    "# position counts ---------------------------\n",
    "Pos_count = df_fpw['position'].value_counts()\n",
    "\n",
    "# creating a box plot to visualize data -----------------------\n",
    "\n",
    "#plt.figure(figsize = (10,6))\n",
    "#sns.boxplot(x=df_fpw['position'], y= df_fpw['ppg'], palette='Set2')\n",
    "#plt.title('Dis of ppg by pos')\n",
    "#plt.xlabel('POS')\n",
    "#plt.ylabel('PPG')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# shooting stats by pos\n",
    "\n",
    "#Shooting = df_fpw.groupby('position').agg({ '3P':'mean','2p':'mean','fg': 'mean', 'ft': 'mean'})\n",
    "    \n",
    "# bar chart for shooting stats-----------------------\n",
    "\n",
    "#Shooting.plot(kind = 'bar', figsize=(12,5), colormap = 'coolwarm')\n",
    "#plt.title('Shooting Efficiency by Position')\n",
    "#plt.xlabel('Position')\n",
    "#plt.xticks(rotation=0)\n",
    "#plt.ylabel('Shooting Percentage')\n",
    "#plt.show()\n",
    "\n",
    "# separate starters and bench players ---------------------\n",
    "# Starters = df_fpw[(df_fpw['gs'] >= 41)]\n",
    "# Bench = df_fpw[(df_fpw['gs'] < 41)]\n",
    "\n",
    "\n",
    "#shoot_starters = df_fpw[(df_fpw['gs'] >= 41)].groupby('position').agg({ '3P':'mean','2p':'mean','fg': 'mean', 'ft': 'mean'})\n",
    "#shoot_bench = df_fpw[(df_fpw['gs'] < 41)].groupby('position').agg({ '3P':'mean','2p':'mean','fg': 'mean', 'ft': 'mean'})\n",
    "\n",
    "# z-score -----------------------\n",
    "# df_fpw['ppg_z'] = df_fpw.groupby('position')['ppg'].transform(zscore)\n",
    "\n",
    "# outliers = df_fpw[df_fpw['ppg_z'] > 2][['player', 'position', 'ppg', 'ppg_z']]\n",
    "\n",
    "# time series ------------------------\n",
    "#Trend_Pos_stats = df_sea.groupby(['Year','Pos'])[['ppg','asg','rbg','stl','blk']].agg(['mean'}).unstack()\n",
    "\n",
    "#Trend_Pos_PPG = df_sea.groupby(['Year','Pos'])[['PPG']].agg(['mean']).unstack()\n",
    "\n",
    "#Trend_Pos_PPG.plot(figsize=(10,5), marker = 'o')\n",
    "#plt.title('PPG Stats Trends by position over time')\n",
    "#plt.xlabel('Year')\n",
    "#plt.ylabel('Major Stats')\n",
    "#plt.legend(title='Position')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "5599fa6d-6e5f-448a-8dcb-5cac5084171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draft pick analysis\n",
    "\n",
    "# get dataset for pick analysis\n",
    "df_pick = df_ndd.merge(df_as, on='player', how = 'left').merge(df_pm, on='player', how = 'left')\n",
    "df_pick = df_pick.fillna(0)\n",
    "\n",
    "\n",
    "# filter columns\n",
    "df_pick = df_pick[['player','pick_overall', 'team_id','college_name','height','weight', 'seasons', 'Pos', \n",
    "\"ppg\", 'asg', 'rbg', 'fg', '3p_y','2p', 'ft', 'g', 'USG', 'PER', 'ws', 'bpm', 'vorp', 'TS', 'birth_state']]\n",
    "\n",
    "# filter and groupby pick\n",
    "pick = df_pick[df_pick['pick_overall'] <= 60]\n",
    "pick_ppg = pick.groupby('pick_overall', as_index = False)['ppg'].mean()\n",
    "\n",
    "df_pick_p = df_pick[(df_pick['PER'] != 0) & (df_pick['pick_overall'] <= 60)]\n",
    "pick_per = df_pick_p.groupby('pick_overall', as_index = False)['PER'].mean()\n",
    "\n",
    "# visualize the data\n",
    "\n",
    "# scatter plot of ppg by pick\n",
    "#plt.scatter(pick_ppg['pick_overall'], pick_ppg['ppg'])\n",
    "#plt.xlabel('pick_overall')\n",
    "#plt.ylabel('PPG')\n",
    "#plt.title('PPG Stats Trends by pick overall')\n",
    "#plt.show()\n",
    "\n",
    "# scatter of PER by pick\n",
    "#plt.scatter(pick_per['pick_overall'], pick_per['PER'])\n",
    "#plt.xlabel('pick_overall')\n",
    "#plt.ylabel('PER')\n",
    "#plt.title('PER Trends by pick overall')\n",
    "#plt.show()\n",
    "\n",
    "# see which teams draft the best scorers\n",
    "\n",
    "team = pick_p\n",
    "team_p = team.groupby('team_id', as_index = False)[['ppg', 'PER']].mean()\n",
    "team_p = team_p.sort_values(by='ppg', ascending = False)\n",
    "\n",
    "#team_p\n",
    "\n",
    "# updating players without a position based on height\n",
    "def assign_position(height):\n",
    "    if height < 6.3:\n",
    "        return 'Guard'\n",
    "    elif 6.3 < height < 6.8:\n",
    "        return 'Wing'\n",
    "    else:\n",
    "        return 'Big'\n",
    "        \n",
    "df_pick['Pos'] = df_pick.apply(lambda row: assign_position(row['height']) if row['Pos'] == 0 else row['Pos'], axis =1)\n",
    "\n",
    "#sns.boxplot(x=df_pick['Pos'], y = df_pick['ppg'], hue=pd.cut(df_pick['pick_overall'], bins = [1, 10, 30, 60]))\n",
    "\n",
    "# longevity\n",
    "\n",
    "#sns.lineplot(x=pick['pick_overall'], y=pick['seasons'])\n",
    "#plt.title('Seasons Played by Pick Number')\n",
    "#plt.show()\n",
    "\n",
    "# bust rate\n",
    "def cat_pick(pick_):\n",
    "    if pick_ <= 10:\n",
    "        return 'Top 10'\n",
    "    elif pick_ <= 20:\n",
    "        return 'Mid 1st round'\n",
    "    elif pick_ <= 30:\n",
    "        return 'Late 1st round'\n",
    "    else:\n",
    "        return '2nd round'\n",
    "\n",
    "df_pick['pick_range'] = df_pick['pick_overall'].apply(cat_pick)\n",
    "pick_order = ['Top 10', 'Mid 1st round', 'Late 1st round', '2nd round']\n",
    "\n",
    "df_pick['PER'] = df_pick.apply(\n",
    "    lambda row: df_pick[(df_pick['Pos'] == row['Pos']) & (df_pick['pick_range'] == row['pick_range'])]['PER'].median() \n",
    "    if row['PER'] == 0 else row['PER'], axis=1 )\n",
    "#df_pick['pick_range'] = pd.Categorical(df_pick['pick_range'], categories = pick_order, ordered = True)\n",
    "\n",
    "\n",
    "#bust_rates = df_pick.groupby('pick_range')['bust'].mean().reset_index()\n",
    "#bust_rates.columns = ['pick_range', 'bust_rate']\n",
    "#bust_rates.sort_values(by='bust_rate', ascending = True)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(8,5))\n",
    "#sns.barplot(x=bust_rates['pick_range'], y=bust_rates['bust_rate'] * 100, palette = 'coolwarm', order = pick_order)\n",
    "#plt.xlabel('Draft Pick Range')\n",
    "#plt.ylabel('Bust Rate')\n",
    "#plt.title('NBA draft bust rates by pick range')\n",
    "#plt.ylim(0,70)\n",
    "#plt.show()\n",
    "\n",
    "# can show the bust rate by position and height\n",
    "\n",
    "# use z-score to see which players outperformed and underpeformed\n",
    "df_pick['per_z'] = df_pick.groupby('pick_range')['PER'].transform(lambda x: zscore (x, ddof=1))\n",
    "\n",
    "def perf_cat(z):\n",
    "    if z > 1.5:\n",
    "        return 'Overperformed'\n",
    "    elif z < -1.5:\n",
    "        return 'Underperformed'\n",
    "    else:\n",
    "        return 'Average'\n",
    "\n",
    "df_pick['per_p'] = df_pick['per_z'].apply(perf_cat)\n",
    "per_filter = df_pick[df_pick['PER'] != 0]\n",
    "df_pick_z = per_filter[['player', 'pick_overall', 'pick_range', 'PER', 'per_z', 'per_p']]\n",
    "\n",
    "ops = df_pick_z[(df_pick_z['per_p'] == 'Overperformed')]\n",
    "#ops\n",
    "\n",
    "df_pick['bust'] = (\n",
    "(df_pick['ppg'] < df_pick.groupby('pick_range')['ppg'].transform('mean') - 1.5 * df_pick.groupby('pick_range')['ppg'].transform('std')) | \\\n",
    "(df_pick['PER'] < df_pick.groupby('pick_range')['PER'].transform('mean') - 1.5 * df_pick.groupby('pick_range')['PER'].transform('std')) | \\\n",
    "(df_pick['seasons'] < 3))\n",
    "\n",
    "df_pick['star'] = (\n",
    "(df_pick['ppg'] > df_pick.groupby('pick_range')['ppg'].transform('mean') + 1.5 * df_pick.groupby('pick_range')['ppg'].transform('std')) &\n",
    "(df_pick['PER'] > df_pick.groupby('pick_range')['PER'].transform('mean') + 1.5 * df_pick.groupby('pick_range')['PER'].transform('std')) &\n",
    "(df_pick['PER'] != 0) &\n",
    "(df_pick['seasons'] > 3))\n",
    "# extra- college, birth state, more height , more pos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "id": "101d35df-8d9e-42b4-a6a8-78451853cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "\n",
    "#\n",
    "corr_pick = per_filter[['pick_overall', 'ppg', 'TS' ,'PER', 'ws', 'bpm', 'vorp', 'USG']]\n",
    "\n",
    "corr_m = corr_pick.corr()\n",
    "\n",
    "# \n",
    "corr_pos = per_filter[['Pos', 'ppg', 'TS' ,'PER', 'ws', 'bpm', 'vorp', 'USG']]\n",
    "\n",
    "#corr_m2 = corr_pos.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "id": "6b89a4b5-e27d-4f77-82b4-c9059e8bd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create archetypes by clustering\n",
    "\n",
    "stats = per_filter[['ppg', 'PER', 'TS', 'USG', 'ws', 'bpm', 'vorp']]\n",
    "\n",
    "df_clus = stats.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_clus_scal = scaler.fit_transform(df_clus)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 42, n_init = 10)\n",
    "df_clus['cluster'] = kmeans.fit_predict(df_clus_scal)\n",
    "\n",
    "#df_clus['cluster'].value_counts()\n",
    "\n",
    "#df_clus.groupby('cluster')[['ppg', 'PER', 'TS', 'USG', 'ws', 'bpm', 'vorp']]\n",
    "\n",
    "#plt.figure(figsize = (10,6))\n",
    "#sns.scatterplot(x=df_clus['ppg'], y = df_clus['PER'], hue =df_clus['cluster'], palette = 'viridis')\n",
    "#plt.xlabel('PPG')\n",
    "#plt.ylabel('PER')\n",
    "#plt.title('NBA Player Cluster')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "2f8c3626-bdf7-4ac4-ab65-b0a024bb93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export datasets to excel files\n",
    "\n",
    "#df_sea.to_excel(r\"C:\\Users\\shero\\Downloads\\sea.xlsx\", index= False)\n",
    "#df_cpl.to_excel(r\"C:\\Users\\shero\\Downloads\\cpl.xlsx\", index= False)\n",
    "#df_phw.to_excel(r\"C:\\Users\\shero\\Downloads\\phw.xlsx\", index= False)\n",
    "#df_ndd.to_excel(r\"C:\\Users\\shero\\Downloads\\ndd.xlsx\", index= False)\n",
    "\n",
    "#df_ms.to_excel(r\"C:\\Users\\shero\\Downloads\\ms.xlsx\", index= False)\n",
    "#df_pl.to_excel(r\"C:\\Users\\shero\\Downloads\\pl.xlsx\", index= False)\n",
    "#df_pm.to_excel(r\"C:\\Users\\shero\\Downloads\\pm.xlsx\", index= False)\n",
    "#df_as.to_excel(r\"C:\\Users\\shero\\Downloads\\as.xlsx\", index= False)\n",
    "\n",
    "#df_fpw.to_excel(r\"C:\\Users\\shero\\Downloads\\fpw.xlsx\", index= False)\n",
    "df_pick.to_excel(r\"C:\\Users\\shero\\Downloads\\pick.xlsx\", index= False)\n",
    "#df_pick_p.to_excel(r\"C:\\Users\\shero\\Downloads\\pick_p.xlsx\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "4512a119-d561-4136-9dfc-e06635b33abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpw_gs = df_fpw[(df_fpw['gs'].isna() | (df_fpw['gs'])) == 0 & (df_fpw['g'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc506c-7ac2-44d1-8f2e-22d296d31b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
